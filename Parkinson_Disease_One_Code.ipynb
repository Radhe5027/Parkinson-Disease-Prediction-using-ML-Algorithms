{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55ec0bb",
   "metadata": {},
   "source": [
    "### No SMOTE, Random State = 42, All ML Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c152c589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkinson Disease: 564 Healthy: 192\n",
      "XGBoost Accuracy: 88.1578947368421\n",
      "XGBoost F1 Score: 0.9243697478991597\n",
      "XGBoost True Positive Rate (TPR): 0.9649122807017544\n",
      "XGBoost False Positive Rate (FPR): 0.3684210526315789\n",
      "XGBoost ROC-AUC Score: 0.9162049861495845\n",
      "                 Predicted Healthy  Predicted Parkinsons\n",
      "True Healthy                    24                    14\n",
      "True Parkinsons                  4                   110\n",
      "---------------------------------------\n",
      "Model: SVM\n",
      "Accuracy: 0.83\n",
      "F1 Score: 0.89\n",
      "ROC-AUC Score: 0.69\n",
      "True Positive Rate (TPR): 0.99\n",
      "False Positive Rate (FPR): 0.62\n",
      "Confusion Matrix:\n",
      "[[ 23  38]\n",
      " [  1 165]]\n",
      "---------------------------------------\n",
      "Model: KNN\n",
      "Accuracy: 0.86\n",
      "F1 Score: 0.91\n",
      "ROC-AUC Score: 0.79\n",
      "True Positive Rate (TPR): 0.94\n",
      "False Positive Rate (FPR): 0.36\n",
      "Confusion Matrix:\n",
      "[[ 39  22]\n",
      " [ 10 156]]\n",
      "---------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 0.85\n",
      "F1 Score: 0.91\n",
      "ROC-AUC Score: 0.74\n",
      "True Positive Rate (TPR): 0.98\n",
      "False Positive Rate (FPR): 0.49\n",
      "Confusion Matrix:\n",
      "[[ 31  30]\n",
      " [  4 162]]\n",
      "---------------------------------------\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.87\n",
      "F1 Score: 0.92\n",
      "ROC-AUC Score: 0.77\n",
      "True Positive Rate (TPR): 0.98\n",
      "False Positive Rate (FPR): 0.43\n",
      "Confusion Matrix:\n",
      "[[ 35  26]\n",
      " [  4 162]]\n",
      "---------------------------------------\n",
      "Model: Naive Bayes\n",
      "Accuracy: 0.76\n",
      "F1 Score: 0.83\n",
      "ROC-AUC Score: 0.73\n",
      "True Positive Rate (TPR): 0.80\n",
      "False Positive Rate (FPR): 0.34\n",
      "Confusion Matrix:\n",
      "[[ 40  21]\n",
      " [ 34 132]]\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Lenovo\\\\Downloads\\\\archive (2)\\\\pd_speech_features.csv\")\n",
    "\n",
    "# Extract features and labels\n",
    "features = df.iloc[:, 1:-1].values\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "print(\"Parkinson Disease:\", labels[labels == 1].shape[0], \"Healthy:\", labels[labels == 0].shape[0])\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler((-1, 1))\n",
    "x = scaler.fit_transform(features)\n",
    "y = labels\n",
    "\n",
    "# Split the data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the XGBoost classifier\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss')\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using XGBoost\n",
    "xgb_y_pred = xgb_model.predict(x_test)\n",
    "\n",
    "# Calculate the accuracy score for XGBoost\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
    "print(\"XGBoost Accuracy:\", xgb_accuracy * 100)\n",
    "\n",
    "# Create a confusion matrix for XGBoost\n",
    "xgb_confusion = confusion_matrix(y_test, xgb_y_pred)\n",
    "\n",
    "# Calculate F1 score for XGBoost\n",
    "xgb_f1 = f1_score(y_test, xgb_y_pred)\n",
    "print(\"XGBoost F1 Score:\", xgb_f1)\n",
    "\n",
    "# Calculate True Positive Rate (TPR) and False Positive Rate (FPR) for XGBoost\n",
    "xgb_TP = xgb_confusion[1, 1]\n",
    "xgb_FN = xgb_confusion[1, 0]\n",
    "xgb_FP = xgb_confusion[0, 1]\n",
    "xgb_TN = xgb_confusion[0, 0]\n",
    "\n",
    "xgb_TPR = xgb_TP / (xgb_TP + xgb_FN)\n",
    "xgb_FPR = xgb_FP / (xgb_FP + xgb_TN)\n",
    "\n",
    "print(\"XGBoost True Positive Rate (TPR):\", xgb_TPR)\n",
    "print(\"XGBoost False Positive Rate (FPR):\", xgb_FPR)\n",
    "\n",
    "# Calculate ROC-AUC Score for XGBoost\n",
    "xgb_roc_auc = roc_auc_score(y_test, xgb_model.predict_proba(x_test)[:, 1])\n",
    "print(\"XGBoost ROC-AUC Score:\", xgb_roc_auc)\n",
    "\n",
    "# Create a DataFrame for the confusion matrix of XGBoost\n",
    "xgb_confusion_df = pd.DataFrame(xgb_confusion, columns=['Predicted Healthy', 'Predicted Parkinsons'], index=['True Healthy', 'True Parkinsons'])\n",
    "print(xgb_confusion_df)\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "# Split the data into training and testing sets for other models\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=30, max_depth=10, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, solver='liblinear', random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for model_name, model in models.items():\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    tpr = confusion[1, 1] / (confusion[1, 1] + confusion[1, 0])\n",
    "    fpr = confusion[0, 1] / (confusion[0, 1] + confusion[0, 0])\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "    print(f\"True Positive Rate (TPR): {tpr:.2f}\")\n",
    "    print(f\"False Positive Rate (FPR): {fpr:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    print(\"---------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bafa6eb",
   "metadata": {},
   "source": [
    "###  SMOTE, Random State = 42, All ML Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78a7b974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkinson Disease: 564 Healthy: 192\n",
      "Model: SVM\n",
      "Accuracy: 0.81\n",
      "F1 Score: 0.82\n",
      "ROC-AUC Score: 0.81\n",
      "True Positive Rate (TPR): 0.81\n",
      "False Positive Rate (FPR): 0.18\n",
      "Confusion Matrix:\n",
      "[[135  30]\n",
      " [ 33 141]]\n",
      "---------------------------------------\n",
      "Model: KNN\n",
      "Accuracy: 0.89\n",
      "F1 Score: 0.88\n",
      "ROC-AUC Score: 0.89\n",
      "True Positive Rate (TPR): 0.79\n",
      "False Positive Rate (FPR): 0.00\n",
      "Confusion Matrix:\n",
      "[[165   0]\n",
      " [ 37 137]]\n",
      "---------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 0.96\n",
      "F1 Score: 0.96\n",
      "ROC-AUC Score: 0.96\n",
      "True Positive Rate (TPR): 0.93\n",
      "False Positive Rate (FPR): 0.02\n",
      "Confusion Matrix:\n",
      "[[162   3]\n",
      " [ 12 162]]\n",
      "---------------------------------------\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.88\n",
      "F1 Score: 0.88\n",
      "ROC-AUC Score: 0.88\n",
      "True Positive Rate (TPR): 0.83\n",
      "False Positive Rate (FPR): 0.07\n",
      "Confusion Matrix:\n",
      "[[154  11]\n",
      " [ 30 144]]\n",
      "---------------------------------------\n",
      "Model: Naive Bayes\n",
      "Accuracy: 0.79\n",
      "F1 Score: 0.79\n",
      "ROC-AUC Score: 0.79\n",
      "True Positive Rate (TPR): 0.80\n",
      "False Positive Rate (FPR): 0.22\n",
      "Confusion Matrix:\n",
      "[[128  37]\n",
      " [ 35 139]]\n",
      "---------------------------------------\n",
      "Model: XGBoost\n",
      "Accuracy: 0.95\n",
      "F1 Score: 0.95\n",
      "ROC-AUC Score: 0.95\n",
      "True Positive Rate (TPR): 0.94\n",
      "False Positive Rate (FPR): 0.04\n",
      "Confusion Matrix:\n",
      "[[159   6]\n",
      " [ 11 163]]\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Lenovo\\\\Downloads\\\\archive (2)\\\\pd_speech_features.csv\")\n",
    "\n",
    "# Extract features and labels\n",
    "features = df.iloc[:, 1:-1].values\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "print(\"Parkinson Disease:\", labels[labels == 1].shape[0], \"Healthy:\", labels[labels == 0].shape[0])\n",
    "\n",
    "# Scale the features to a similar range (e.g., [0, 1]) using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Apply SMOTE to balance the data\n",
    "smote = SMOTE(random_state=42)\n",
    "features_resampled, labels_resampled = smote.fit_resample(features_scaled, labels)\n",
    "\n",
    "# Split the data into training and testing sets with random split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_resampled, labels_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=30, max_depth=10, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, solver='liblinear', random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for model_name, model in models.items():\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    tpr = confusion[1, 1] / (confusion[1, 1] + confusion[1, 0])\n",
    "    fpr = confusion[0, 1] / (confusion[0, 1] + confusion[0, 0])\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "    print(f\"True Positive Rate (TPR): {tpr:.2f}\")\n",
    "    print(f\"False Positive Rate (FPR): {fpr:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    print(\"---------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d96cfbf",
   "metadata": {},
   "source": [
    "###  SMOTE, PCA, Random State = 42, All ML Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a2101de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Features: 753\n",
      "Number of Features after PCA: 116\n",
      "Number of Features Removed: 637\n",
      "Model: SVM\n",
      "Accuracy: 0.95\n",
      "F1 Score: 0.95\n",
      "ROC-AUC Score: 0.95\n",
      "True Positive Rate (TPR): 0.92\n",
      "False Positive Rate (FPR): 0.02\n",
      "Confusion Matrix:\n",
      "[[161   4]\n",
      " [ 14 160]]\n",
      "---------------------------------------\n",
      "Model: KNN\n",
      "Accuracy: 0.89\n",
      "F1 Score: 0.88\n",
      "ROC-AUC Score: 0.90\n",
      "True Positive Rate (TPR): 0.79\n",
      "False Positive Rate (FPR): 0.00\n",
      "Confusion Matrix:\n",
      "[[165   0]\n",
      " [ 36 138]]\n",
      "---------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 0.92\n",
      "F1 Score: 0.92\n",
      "ROC-AUC Score: 0.92\n",
      "True Positive Rate (TPR): 0.92\n",
      "False Positive Rate (FPR): 0.07\n",
      "Confusion Matrix:\n",
      "[[153  12]\n",
      " [ 14 160]]\n",
      "---------------------------------------\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.86\n",
      "F1 Score: 0.86\n",
      "ROC-AUC Score: 0.87\n",
      "True Positive Rate (TPR): 0.80\n",
      "False Positive Rate (FPR): 0.07\n",
      "Confusion Matrix:\n",
      "[[153  12]\n",
      " [ 34 140]]\n",
      "---------------------------------------\n",
      "Model: Naive Bayes\n",
      "Accuracy: 0.79\n",
      "F1 Score: 0.78\n",
      "ROC-AUC Score: 0.79\n",
      "True Positive Rate (TPR): 0.72\n",
      "False Positive Rate (FPR): 0.14\n",
      "Confusion Matrix:\n",
      "[[142  23]\n",
      " [ 48 126]]\n",
      "---------------------------------------\n",
      "Model: XGBoost\n",
      "Accuracy: 0.94\n",
      "F1 Score: 0.94\n",
      "ROC-AUC Score: 0.94\n",
      "True Positive Rate (TPR): 0.91\n",
      "False Positive Rate (FPR): 0.02\n",
      "Confusion Matrix:\n",
      "[[161   4]\n",
      " [ 16 158]]\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Lenovo\\\\Downloads\\\\archive (2)\\\\pd_speech_features.csv\")\n",
    "\n",
    "# Extract features and labels\n",
    "features = df.iloc[:, 1:-1].values\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "print(\"Total Number of Features:\", features.shape[1])\n",
    "\n",
    "# Scale the features to a similar range (e.g., [0, 1]) using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "features_pca = pca.fit_transform(features_scaled)\n",
    "\n",
    "print(\"Number of Features after PCA:\", features_pca.shape[1])\n",
    "print(\"Number of Features Removed:\", features.shape[1] - features_pca.shape[1])\n",
    "\n",
    "# Apply SMOTE to balance the data using PCA-transformed features\n",
    "smote = SMOTE(random_state=42)\n",
    "features_resampled_pca, labels_resampled = smote.fit_resample(features_pca, labels)\n",
    "\n",
    "# Split the data into training and testing sets with random split using PCA-transformed features\n",
    "x_train_pca, x_test_pca, y_train, y_test = train_test_split(features_resampled_pca, labels_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=30, max_depth=10, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, solver='liblinear', random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models using PCA-transformed features\n",
    "for model_name, model in models.items():\n",
    "    model.fit(x_train_pca, y_train)\n",
    "    y_pred = model.predict(x_test_pca)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    tpr = confusion[1, 1] / (confusion[1, 1] + confusion[1, 0])\n",
    "    fpr = confusion[0, 1] / (confusion[0, 1] + confusion[0, 0])\n",
    "\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "    print(f\"True Positive Rate (TPR): {tpr:.2f}\")\n",
    "    print(f\"False Positive Rate (FPR): {fpr:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    print(\"---------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e7ab6",
   "metadata": {},
   "source": [
    "### SMOTE, Stratified, All ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b0d5d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkinson Disease: 564 Healthy: 192\n",
      "Model: SVM\n",
      "Accuracy: 0.82\n",
      "F1 Score: 0.81\n",
      "ROC-AUC Score: 0.82\n",
      "True Positive Rate (TPR): 0.78\n",
      "False Positive Rate (FPR): 0.14\n",
      "Confusion Matrix:\n",
      "[[147  23]\n",
      " [ 38 131]]\n",
      "---------------------------------------\n",
      "Model: KNN\n",
      "Accuracy: 0.81\n",
      "F1 Score: 0.77\n",
      "ROC-AUC Score: 0.81\n",
      "True Positive Rate (TPR): 0.64\n",
      "False Positive Rate (FPR): 0.02\n",
      "Confusion Matrix:\n",
      "[[167   3]\n",
      " [ 61 108]]\n",
      "---------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 0.93\n",
      "F1 Score: 0.93\n",
      "ROC-AUC Score: 0.93\n",
      "True Positive Rate (TPR): 0.93\n",
      "False Positive Rate (FPR): 0.06\n",
      "Confusion Matrix:\n",
      "[[159  11]\n",
      " [ 12 157]]\n",
      "---------------------------------------\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.87\n",
      "F1 Score: 0.87\n",
      "ROC-AUC Score: 0.87\n",
      "True Positive Rate (TPR): 0.86\n",
      "False Positive Rate (FPR): 0.12\n",
      "Confusion Matrix:\n",
      "[[149  21]\n",
      " [ 24 145]]\n",
      "---------------------------------------\n",
      "Model: Naive Bayes\n",
      "Accuracy: 0.75\n",
      "F1 Score: 0.73\n",
      "ROC-AUC Score: 0.75\n",
      "True Positive Rate (TPR): 0.69\n",
      "False Positive Rate (FPR): 0.18\n",
      "Confusion Matrix:\n",
      "[[139  31]\n",
      " [ 53 116]]\n",
      "---------------------------------------\n",
      "Model: XGBoost\n",
      "Accuracy: 0.95\n",
      "F1 Score: 0.95\n",
      "ROC-AUC Score: 0.95\n",
      "True Positive Rate (TPR): 0.95\n",
      "False Positive Rate (FPR): 0.05\n",
      "Confusion Matrix:\n",
      "[[162   8]\n",
      " [  8 161]]\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Lenovo\\\\Downloads\\\\archive (2)\\\\pd_speech_features.csv\")\n",
    "\n",
    "# Extract features and labels\n",
    "features = df.iloc[:, 1:-1].values\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "print(\"Parkinson Disease:\", labels[labels == 1].shape[0], \"Healthy:\", labels[labels == 0].shape[0])\n",
    "\n",
    "# Scale the features to a similar range (e.g., [0, 1]) using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Apply SMOTE to balance the data\n",
    "smote = SMOTE(random_state=42)\n",
    "features_resampled, labels_resampled = smote.fit_resample(features_scaled, labels)\n",
    "\n",
    "# Split the data into training and testing sets with stratified split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_resampled, labels_resampled, test_size=0.3, stratify=labels_resampled)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=30, max_depth=10),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, solver='liblinear'),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for model_name, model in models.items():\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    tpr = confusion[1, 1] / (confusion[1, 1] + confusion[1, 0])\n",
    "    fpr = confusion[0, 1] / (confusion[0, 1] + confusion[0, 0])\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "    print(f\"True Positive Rate (TPR): {tpr:.2f}\")\n",
    "    print(f\"False Positive Rate (FPR): {fpr:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    print(\"---------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e801bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
